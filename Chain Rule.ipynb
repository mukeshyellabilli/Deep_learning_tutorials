{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMZa/ihiLRiQDWAdqDV/PGN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **CHAIN RULE**\n","\n","\n"],"metadata":{"id":"BGEtvFsdO9Z9"}},{"cell_type":"markdown","source":["In deep learning, the **chain rule** helps us compute derivatives in complex models (like neural networks) where many functions are combined or \"chained\" together. This is crucial for training neural networks using *backpropagation*, which relies on gradients (derivatives) to update the model's weights and reduce the error.\n","\n","### Simple Explanation of the Chain Rule\n","\n","The chain rule states that if you have a function made up of other functions, you can find the derivative of the whole function by multiplying the derivatives of each part.\n","\n","In mathematical terms:\n","If \\( y = f(g(x)) \\), then:\n","\\[\n","\\frac{dy}{dx} = f'(g(x)) \\times g'(x)\n","\\]\n","This means you first find the derivative of the outer function \\( f \\) with respect to the inner function \\( g(x) \\), then multiply it by the derivative of the inner function \\( g(x) \\) with respect to \\( x \\).\n","\n","### Example in Simple Language\n","\n","Let's say we have two simple functions:\n","1. \\( g(x) = x^2 \\)\n","2. \\( f(g) = g + 3 \\)\n","\n","So, our combined function \\( y \\) is:\n","\n","\\[\n","y = f(g(x)) = x^2 + 3\n","\\]\n","\n","**Goal:** Find the derivative of \\( y \\) with respect to \\( x \\).\n","\n","**Step 1:** Differentiate the outer function \\( f(g) = g + 3 \\) with respect to \\( g \\).\n","\\[\n","f'(g) = 1\n","\\]\n","\n","**Step 2:** Differentiate the inner function \\( g(x) = x^2 \\) with respect to \\( x \\).\n","\\[\n","g'(x) = 2x\n","\\]\n","\n","**Step 3:** Apply the chain rule:\n","\\[\n","\\frac{dy}{dx} = f'(g(x)) \\times g'(x) = 1 \\times 2x = 2x\n","\\]\n","\n","So, the derivative \\( \\frac{dy}{dx} = 2x \\).\n","\n","### How This Applies in Deep Learning\n","\n","In a neural network, each layer applies a function to the previous layer's output. The chain rule lets us calculate how changing weights in earlier layers affects the final output (and thus the error). By chaining derivatives layer-by-layer, we can find the exact gradient needed to adjust each weight and improve the model's accuracy."],"metadata":{"id":"R0HATSuoOzPm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fpN28immOtzb"},"outputs":[],"source":[]}]}